{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Dependencies\n\nBegin by importing the necessary libraries","metadata":{}},{"cell_type":"code","source":"# Data storage\nfrom google.cloud import bigquery\n\n# Data analysis\nimport pandas as pd\n\n# Data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nsns.set_style('darkgrid')","metadata":{"execution":{"iopub.status.busy":"2022-08-02T08:59:45.570955Z","iopub.execute_input":"2022-08-02T08:59:45.572181Z","iopub.status.idle":"2022-08-02T08:59:45.582665Z","shell.execute_reply.started":"2022-08-02T08:59:45.572116Z","shell.execute_reply":"2022-08-02T08:59:45.581055Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration\n\nExplore the StackOverflow dataset from BigQuery's public data archives","metadata":{}},{"cell_type":"code","source":"# Initialize a client object to project ID\nproject_id = 'trim-axle-358009'\nclient = bigquery.Client(project=project_id)\n\n# Construct a reference to the \"stackoverflow\" dataset\ndataset_ref = client.dataset('stackoverflow', project='bigquery-public-data')\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)","metadata":{"execution":{"iopub.status.busy":"2022-08-02T08:59:45.585173Z","iopub.execute_input":"2022-08-02T08:59:45.586038Z","iopub.status.idle":"2022-08-02T08:59:46.699442Z","shell.execute_reply.started":"2022-08-02T08:59:45.585983Z","shell.execute_reply":"2022-08-02T08:59:46.698022Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Print every table ID in the dataset\ntables = list(client.list_tables(dataset))\nfor table in tables:  \n    print(table.table_id)","metadata":{"execution":{"iopub.status.busy":"2022-08-02T08:59:46.701275Z","iopub.execute_input":"2022-08-02T08:59:46.701695Z","iopub.status.idle":"2022-08-02T08:59:46.985833Z","shell.execute_reply.started":"2022-08-02T08:59:46.701659Z","shell.execute_reply":"2022-08-02T08:59:46.984228Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# Question Prompt\nPosts (questions & answers) on StackOverflow been declining since 2014.","metadata":{}},{"cell_type":"code","source":"# Query to select question & answer counts as a function of time\nquery = \"\"\"\n        WITH q AS (\n            SELECT EXTRACT(YEAR FROM creation_date) AS year, COUNT(*) AS num_questions\n            FROM `bigquery-public-data.stackoverflow.posts_questions`\n            GROUP BY year\n        ), \n        a AS (\n            SELECT EXTRACT(YEAR FROM creation_date) AS year, COUNT(*) AS num_answers\n            FROM `bigquery-public-data.stackoverflow.posts_answers`\n            GROUP BY year\n        ),\n        cte AS (\n            SELECT year, num_questions, num_answers,\n            FROM q\n            JOIN a\n                USING(year)\n        )\n        SELECT \n            c1.year, \n            c1.num_questions,\n            ROUND((c1.num_questions - c2.num_questions) / c1.num_questions * 100, 2) AS q_percent_diff,\n            c1.num_answers, \n            ROUND((c1.num_answers - c2.num_answers) / c1.num_answers * 100, 2) AS a_percent_diff,\n        FROM cte AS c1\n        LEFT JOIN cte AS c2\n            ON c1.year = c2.year + 1\n        ORDER BY c1.year\n        \"\"\"\n\n# Set up the query (cancel if greater than 10 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nquery_job = client.query(query, job_config=safe_config)\n\n# API request - run the query, then convert the results to a pandas DataFrame\ndf = query_job.to_dataframe()\n\n# Print the resulting DataFrame\ndf","metadata":{"execution":{"iopub.status.busy":"2022-08-02T08:59:46.989839Z","iopub.execute_input":"2022-08-02T08:59:46.990377Z","iopub.status.idle":"2022-08-02T08:59:48.263629Z","shell.execute_reply.started":"2022-08-02T08:59:46.990328Z","shell.execute_reply":"2022-08-02T08:59:48.262255Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# drop 2022 data since it's incomplete\ndf.drop(index=14, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-02T08:59:48.265411Z","iopub.execute_input":"2022-08-02T08:59:48.265851Z","iopub.status.idle":"2022-08-02T08:59:48.273589Z","shell.execute_reply.started":"2022-08-02T08:59:48.265800Z","shell.execute_reply":"2022-08-02T08:59:48.271976Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Make line plot\nfig = plt.figure()\nax = df.plot(x='year', y=['num_questions', 'num_answers'], kind='line', linewidth=5, figsize=(15, 15), fontsize=20)\n\n# Customize plot\nax.set_title('Number of Q&A\\'s Over Time', fontsize=28)\nax.set_xlabel('')\nax.set_ylabel('Count (Millions)', fontsize=25)\nax.set_yticks(ticks=[0, 500000, 1000000, 1500000, 2000000, 2500000, 3000000, 3500000], labels=[0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5])\nax.legend(['Questions', 'Answers'], fontsize=25)\n\n# Save plot\nplt.savefig('num_qna.png')","metadata":{"execution":{"iopub.status.busy":"2022-08-02T08:59:48.275406Z","iopub.execute_input":"2022-08-02T08:59:48.275989Z","iopub.status.idle":"2022-08-02T08:59:48.893738Z","shell.execute_reply.started":"2022-08-02T08:59:48.275930Z","shell.execute_reply":"2022-08-02T08:59:48.892071Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Drop 2008 data since there's no change\ndf.drop(index=0, inplace=True)\n\n# Make bar plot\nfig = plt.figure()\nax = df.plot(x='year', y=['q_percent_diff', 'a_percent_diff'], kind='bar', figsize=(15, 15), fontsize=20)\n\n# Customize plot\nax.set_title('Change in Q&A\\'s Over Time', fontsize=28)\nax.set_xlabel('')\nax.set_ylabel('Change (Percent)', fontsize=25)\nax.set_yticks(ticks=[-20, 0, 20, 40, 60, 80], labels=['-20%', '0%', '20%', '40%', '60%', '80%'])\nax.legend(['Questions', 'Answers'], fontsize=25)","metadata":{"execution":{"iopub.status.busy":"2022-08-02T08:59:48.895998Z","iopub.execute_input":"2022-08-02T08:59:48.896902Z","iopub.status.idle":"2022-08-02T08:59:49.317081Z","shell.execute_reply.started":"2022-08-02T08:59:48.896853Z","shell.execute_reply":"2022-08-02T08:59:49.315578Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# Root Cause Analysis\n\n### 1. Low-hanging fruit \n\nOne possible explanation is that the easier questions have already been asked, e.g. \"how to make a plot in Python\", \"how to read a csv file in Pandas\", \"how to use SELECT statement in MySQL\", etc.","metadata":{}},{"cell_type":"code","source":"# Query to select most asked about technologies from 2008 to 2014\nquery = \"\"\"\n        WITH cte_1 AS (\n            SELECT\n                SPLIT(tags,'|') AS tech_name\n            FROM `bigquery-public-data.stackoverflow.posts_questions`\n            WHERE EXTRACT(YEAR FROM creation_date) >= 2008 AND EXTRACT(YEAR FROM creation_date) <= 2014\n        ),\n        cte_2 AS (\n            SELECT\n              tags,\n              COUNT(*) AS num_questions\n            FROM cte_1\n            CROSS JOIN UNNEST(tech_name) AS tags\n            GROUP BY tags\n            ORDER BY num_questions DESC\n            LIMIT 10\n        )\n        SELECT \n            tags,\n            num_questions,\n            ROUND(num_questions / SUM(num_questions) OVER() * 100, 2) AS percent_share\n        FROM cte_2\n        ORDER BY num_questions DESC\n        \"\"\"\n\n# Set up the query (cancel if greater than 10 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nquery_job = client.query(query, job_config=safe_config)\n\n# API request - run the query, then convert the results to a pandas DataFrame\ndf = query_job.to_dataframe()\n\n# Print the resulting DataFrame\ndf","metadata":{"execution":{"iopub.status.busy":"2022-08-02T08:59:49.319466Z","iopub.execute_input":"2022-08-02T08:59:49.320164Z","iopub.status.idle":"2022-08-02T08:59:50.486092Z","shell.execute_reply.started":"2022-08-02T08:59:49.320098Z","shell.execute_reply":"2022-08-02T08:59:50.484633Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Pie chart, where the slices will be ordered and plotted counter-clockwise:\nlabels = df.tags\nsizes = df.percent_share\n\n# \"Explode\" the 2nd slice (i.e. 'Python')\nexplode = (0, 0, 0, 0, 0, 0, 0, 0.1, 0, 0) \n\n# Make pie chart\nfig1, ax = plt.subplots(figsize=(15, 17))\nax.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90, textprops={'fontsize': 20})\n\n# Equal aspect ratio ensures that pie is drawn as a circle\nax.axis('equal')\n\n# Customize plot\nax.set_title('Top 10 Technologies (2008 - 2014)', fontsize=28)\n\n# Save plot\nplt.savefig('tech_distribution_2008.png')","metadata":{"execution":{"iopub.status.busy":"2022-08-02T08:59:50.488124Z","iopub.execute_input":"2022-08-02T08:59:50.489695Z","iopub.status.idle":"2022-08-02T08:59:51.039808Z","shell.execute_reply.started":"2022-08-02T08:59:50.489626Z","shell.execute_reply":"2022-08-02T08:59:51.038269Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Query to select most asked about technologies from 2015 to 2022\nquery = \"\"\"\n        WITH cte_1 AS (\n            SELECT\n                SPLIT(tags,'|') AS tech_name\n            FROM `bigquery-public-data.stackoverflow.posts_questions`\n            WHERE EXTRACT(YEAR FROM creation_date) >= 2015 AND EXTRACT(YEAR FROM creation_date) <= 2022\n        ),\n        cte_2 AS (\n            SELECT\n              tags,\n              COUNT(*) AS num_questions\n            FROM cte_1\n            CROSS JOIN UNNEST(tech_name) AS tags\n            GROUP BY tags\n            ORDER BY num_questions DESC\n            LIMIT 10\n        )\n        SELECT \n            tags,\n            num_questions,\n            ROUND(num_questions / SUM(num_questions) OVER() * 100, 2) AS percent_share\n        FROM cte_2\n        ORDER BY num_questions DESC\n        \"\"\"\n\n# Set up the query (cancel if greater than 10 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nquery_job = client.query(query, job_config=safe_config)\n\n# API request - run the query, then convert the results to a pandas DataFrame\ndf = query_job.to_dataframe()\n\n# Print the resulting DataFrame\ndf","metadata":{"execution":{"iopub.status.busy":"2022-08-02T08:59:51.045075Z","iopub.execute_input":"2022-08-02T08:59:51.046630Z","iopub.status.idle":"2022-08-02T08:59:52.227609Z","shell.execute_reply.started":"2022-08-02T08:59:51.046550Z","shell.execute_reply":"2022-08-02T08:59:52.226519Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Pie chart, where the slices will be ordered and plotted counter-clockwise:\nlabels = df.tags\nsizes = df.percent_share\n\n# \"Explode\" the 2nd slice (i.e. 'Python')\nexplode = (0, 0.1, 0, 0, 0, 0, 0, 0, 0, 0) \n\n# Make pie chart\nfig1, ax = plt.subplots(figsize=(15, 17))\nax.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90, textprops={'fontsize': 20})\n\n# Equal aspect ratio ensures that pie is drawn as a circle\nax.axis('equal')\n\n# Customize plot\nax.set_title('Top 10 Technologies (2015 - 2022)', fontsize=28)\n\n# Save plot\nplt.savefig('tech_distribution_2015.png')","metadata":{"execution":{"iopub.status.busy":"2022-08-02T08:59:52.228982Z","iopub.execute_input":"2022-08-02T08:59:52.230234Z","iopub.status.idle":"2022-08-02T08:59:52.767595Z","shell.execute_reply.started":"2022-08-02T08:59:52.230158Z","shell.execute_reply":"2022-08-02T08:59:52.766153Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"Notice from the above plots that the top 10 most asked-about technologies on StackOverflow has remained largely unchanged pre-2014 vs post-2014. This is evidence for our low-hanging fruit hypothesis, since as time goes on, the pool of remaining questions becomes increasingly more niche. ","metadata":{}},{"cell_type":"markdown","source":"### 2. Toxicity\n\nAnother explanation may be that users (especially newer ones) feel increasingly intimidated to post questions, out of fear of being \"downvoted\" or criticized. ","metadata":{}},{"cell_type":"code","source":"# Query to select number of positively scored questions over time\nquery = \"\"\"\n        SELECT\n          EXTRACT(YEAR FROM creation_date) AS year,\n          COUNT(*) AS num_questions,\n          ROUND(SUM(IF(score > 0, 1, 0)) / COUNT(*) * 100, 2) AS percent_positive,\n          ROUND(SUM(IF(score < 0, 1, 0)) / COUNT(*) * 100, 2) AS percent_negative\n        FROM\n          `bigquery-public-data.stackoverflow.posts_questions`\n        GROUP BY year\n        ORDER BY year\n        \"\"\"\n\n# Set up the query (cancel if greater than 10 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nquery_job = client.query(query, job_config=safe_config)\n\n# API request - run the query, then convert the results to a pandas DataFrame\ndf = query_job.to_dataframe()\n\n# Print the resulting DataFrame\ndf","metadata":{"execution":{"iopub.status.busy":"2022-08-02T08:59:52.769036Z","iopub.execute_input":"2022-08-02T08:59:52.769503Z","iopub.status.idle":"2022-08-02T08:59:53.974703Z","shell.execute_reply.started":"2022-08-02T08:59:52.769458Z","shell.execute_reply":"2022-08-02T08:59:53.973105Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Make bar plot\nfig = plt.figure()\nax = df.plot(x='year', y=['percent_positive', 'percent_negative'], kind='bar', figsize=(15, 15), fontsize=20)\n\n# Customize plot\nax.set_title('Question Ratings Over Time', fontsize=28)\nax.set_xlabel('')\nax.set_ylabel('Percentage', fontsize=25)\nax.set_yticks(ticks=[0, 20, 40, 60, 80], labels=['0%', '20%', '40%', '60%', '80%'])\nax.legend(['Positive', 'Negative'], fontsize=25)\n\n# Save plot\nplt.savefig('q_ratings.png')","metadata":{"execution":{"iopub.status.busy":"2022-08-02T08:59:53.976576Z","iopub.execute_input":"2022-08-02T08:59:53.977116Z","iopub.status.idle":"2022-08-02T08:59:54.648769Z","shell.execute_reply.started":"2022-08-02T08:59:53.977066Z","shell.execute_reply":"2022-08-02T08:59:54.647243Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"As evidenced by the declining positive ratings and increasing negative ratings towards questions posted to StackOverflow, it's not hard to imagine why new users may feel intimidated out of fear of asking \"stupid questions\".","metadata":{}},{"cell_type":"markdown","source":"# Does it matter? \n\nDespite the clear downward trend in posts, is there any reason to worry from StackOverflow's perspective? Well, one useful metric to look at to answer this question is new user growth.","metadata":{}},{"cell_type":"code","source":"# Query to select new_user and inactive_user counts as a function of time\nquery = \"\"\"\n        WITH cte_1 AS (\n            SELECT EXTRACT(YEAR FROM creation_date) AS year, COUNT(*) AS num_new_users\n            FROM `bigquery-public-data.stackoverflow.users`\n            GROUP BY year\n        ),\n        cte_2 AS (\n            SELECT \n                c1.year,\n                c1.num_new_users,\n                ROUND((c1.num_new_users - c2.num_new_users) / c1.num_new_users * 100, 2) AS u_percent_diff\n            FROM cte_1 AS c1\n            LEFT JOIN cte_1 AS c2\n                ON c1.year = c2.year + 1\n            ORDER BY c1.year\n        ),\n        cte_3 AS (\n            SELECT \n                EXTRACT(YEAR FROM last_access_date) AS last_accessed_year,\n                2022 - EXTRACT(YEAR FROM last_access_date) AS years_inactive,\n                COUNT(*) AS num_inactive_users\n            FROM `bigquery-public-data.stackoverflow.users`\n            GROUP BY last_accessed_year, years_inactive\n            ORDER BY last_accessed_year\n        )\n        SELECT c_2.year, c_2.num_new_users, c_3.num_inactive_users\n        FROM cte_2 AS c_2\n        JOIN cte_3 AS c_3\n            ON c_2.year = c_3.last_accessed_year\n        ORDER BY c_2.year\n        \"\"\"\n\n# Set up the query (cancel if greater than 10 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nquery_job = client.query(query, job_config=safe_config)\n\n# API request - run the query, then convert the results to a pandas DataFrame\ndf = query_job.to_dataframe()\n\n# Print the resulting DataFrame\ndf","metadata":{"execution":{"iopub.status.busy":"2022-08-02T08:59:54.651113Z","iopub.execute_input":"2022-08-02T08:59:54.651556Z","iopub.status.idle":"2022-08-02T08:59:55.911985Z","shell.execute_reply.started":"2022-08-02T08:59:54.651517Z","shell.execute_reply":"2022-08-02T08:59:55.910550Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# Drop 2022 data since it's incomplete\ndf.drop(index=14, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-02T08:59:55.913951Z","iopub.execute_input":"2022-08-02T08:59:55.914497Z","iopub.status.idle":"2022-08-02T08:59:55.923225Z","shell.execute_reply.started":"2022-08-02T08:59:55.914448Z","shell.execute_reply":"2022-08-02T08:59:55.921622Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# Make line plot\nfig = plt.figure()\nax = df.plot(x='year', y=['num_new_users', 'num_inactive_users'], kind='line', linewidth = 5, figsize=(15, 15), fontsize=20)\n\n# Customize plot\nax.set_title('Number of New & Inactive Users Over Time', fontsize=28)\nax.set_xlabel('')\nax.set_ylabel('Count (Millions)', fontsize=25)\nax.set_yticks(ticks=[0, 500000, 1000000, 1500000, 2000000, 2500000, 3000000, 3500000], labels=[0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5])\nax.legend(['New Users', 'Inactive Users'], fontsize=25)\n\n# Save plot\nplt.savefig('user_activity.png')","metadata":{"execution":{"iopub.status.busy":"2022-08-02T08:59:55.925268Z","iopub.execute_input":"2022-08-02T08:59:55.926089Z","iopub.status.idle":"2022-08-02T08:59:56.496592Z","shell.execute_reply.started":"2022-08-02T08:59:55.926042Z","shell.execute_reply":"2022-08-02T08:59:56.495065Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"Notice, the number of new users per year has been steadily climbing, which may provide StackOverflow a sigh of relief. However, somewhat worryingly, the number of inactive users per year has also been increasing, and in 2019, this user-base surpased the aforementioned new-user growth. While this is to be expected, since more users would naturally lead to more inactive users, the relative gap between the two trends should still be addressed.","metadata":{}},{"cell_type":"markdown","source":"# What Next?\n\nSo, are there any steps StackOverflow can take to accelerate user growth while maintaining user retention?","metadata":{}},{"cell_type":"code","source":"# Query to select avg_questions_per_year as a function of account creation time\nquery = \"\"\"\n        WITH cte_1 AS (\n            SELECT\n                u.id,\n                EXTRACT(YEAR FROM u.creation_date) AS year,\n                COUNT(*) AS num_questions\n            FROM `bigquery-public-data.stackoverflow.users` AS u\n            LEFT JOIN `bigquery-public-data.stackoverflow.posts_questions` AS q\n                ON u.id = q.owner_user_id\n            GROUP BY year, u.id\n        ),\n        cte_2 AS (\n            SELECT\n                id,\n                year,\n                num_questions / (2022 - year + 1) AS num_questions_per_year\n            FROM cte_1\n        )\n        SELECT\n            year,\n            AVG(num_questions_per_year) AS avg_num_questions_per_year\n        FROM cte_2\n        GROUP BY year\n        ORDER BY year\n        \"\"\"\n\n# Set up the query (cancel if greater than 10 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nquery_job = client.query(query, job_config=safe_config)\n\n# API request - run the query, then convert the results to a pandas DataFrame\ndf = query_job.to_dataframe()\n\n# Print the resulting DataFrame\ndf","metadata":{"execution":{"iopub.status.busy":"2022-08-02T08:59:56.499304Z","iopub.execute_input":"2022-08-02T08:59:56.500344Z","iopub.status.idle":"2022-08-02T08:59:57.690211Z","shell.execute_reply.started":"2022-08-02T08:59:56.500291Z","shell.execute_reply":"2022-08-02T08:59:57.688756Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# Make bar plot\nfig = plt.figure()\nax = df.plot(x='year', y='avg_num_questions_per_year', kind='bar', figsize=(15, 15), fontsize=20)\n\n# Customize plot\nax.set_xlabel('Account Created', fontsize=25)\nax.set_ylabel('Average Number of Questions (per year)', fontsize=25)\nax.legend(['Number of Questions'], fontsize=25)\n\n# Save plot\nplt.savefig('avg_questions_vs_age.png')","metadata":{"execution":{"iopub.status.busy":"2022-08-02T08:59:57.692742Z","iopub.execute_input":"2022-08-02T08:59:57.693361Z","iopub.status.idle":"2022-08-02T08:59:58.317055Z","shell.execute_reply.started":"2022-08-02T08:59:57.693302Z","shell.execute_reply":"2022-08-02T08:59:58.315503Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"Interestingly, when looking at the average number of questions per year, with respect to account creation year, we find that users who joined early on during the site's launch in 2008, and users who joined very recently, are the ones posting the most questions! Conversely, users who've been on the site for a few years but are somewhat removed from the early birds are the ones asking the least questions. \n\nThis implies that the early birds may be acting as gatekeepers, with new users initially eager to ask questions, but as time goes on, they become increasingly jaded, and thus less likely to make new posts (some, even abandoning the site altogether). \n\nHence, we suggest that StackOverflow police toxicity by introducing an automated filter for clear and obvious non-answers (e.g. \"why would you even ask that\", \"this question has already been asked stupid\", etc.). Additionally, StackOverflow could provide users with more incentives for asking and answering questions, such as virtual currency that could be exchanged for merch. ","metadata":{}}]}